services:
  vita-web-demo:
    build:
      context: ..
      dockerfile: .devcontainer/Dockerfile
    container_name: vita-web-demo
    ports:
      - "8081:8081"
    volumes:
      - ..:/workspace
      # Mount VITA model from host (download with ./download_model_host.sh first)
      - ../demo_VITA_ckpt:/workspace/demo_VITA_ckpt
      # Custom vLLM files are copied in Dockerfile instead of mounted
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - CUDA_HOME=/usr/local/cuda
      - VLLM_USE_TRITON_FLASH_ATTN=0
      - VLLM_ATTENTION_BACKEND=XFORMERS
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    working_dir: /workspace
    command: >
      bash /workspace/.devcontainer/start.sh
    restart: unless-stopped
    stdin_open: true
    tty: true
